{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c7341e6-3dc4-4851-a4c0-0329649b174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xpress as xp\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a3ce75a-4e74-4c3e-b706-75ffebe0fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we need to feed this model is the following:\n",
    "# 1- List of donor-receipient pairs\n",
    "# 2- List of altruisitic donors\n",
    "# 3- List of nodes = donor-receipient pairs + altruisitic donors\n",
    "# 4- Dictionary of edges with key (\"node1\",\"node2\") and value is the weight of the edge\n",
    "# 5- Dictionary of cycles with key (edge1,edge2,edge3,...) and value is the weight of the cycle i.e., sum of edges in the cycle up to and including length k\n",
    "\n",
    "pairs = [\"P1\", \"P2\", \"P3\"] \n",
    "altruistic_donors = [\"NDD1\"]\n",
    "nodes = pairs + altruistic_donors\n",
    "edges = {(\"NDD1\", \"P1\"): 0.10, \n",
    "         (\"NDD1\", \"P2\"): 0.8,\n",
    "         (\"P1\", \"P3\"): 8, \n",
    "         (\"P2\", \"P3\"): 9,\n",
    "         (\"P3\", \"P1\"): 6,\n",
    "         (\"P1\", \"P2\"): 6}\n",
    "all_cycles = {}\n",
    "\n",
    "\n",
    "# pairs = [\"P1\", \"P2\", \"P3\", \"P4\"] \n",
    "# altruistic_donors = [\"NDD1\"]\n",
    "# nodes = pairs + altruistic_donors\n",
    "# edges = {(\"NDD1\", \"P1\"): 2,\n",
    "#          (\"P1\", \"P2\"): 10, \n",
    "#          (\"P2\", \"P3\"): 10,\n",
    "#          (\"P3\", \"P4\"): 10,\n",
    "#          (\"P4\", \"P1\"): 10}\n",
    "# all_cycles = {}\n",
    "\n",
    "\n",
    "# Create the graph outside the separation algorithm and feed it in whenever we use it so that it doesn't create it every time\n",
    "# instead, it just updates the weights i.e., you only create the graph once!\n",
    "\n",
    "# Construct the directed graph G = (V, E, w) based on supplementary information definition \n",
    "G = nx.DiGraph()\n",
    "for node in nodes:\n",
    "    G.add_node(node)\n",
    "\n",
    "# Add super source 'SUPER' and connect to all NDDs\n",
    "super_source = \"SUPER\"\n",
    "G.add_node(super_source)\n",
    "for u in altruistic_donors:\n",
    "    G.add_edge(super_source, u, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f78ada-fd8e-4541-86df-e081a8121298",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell contains the callbacks and their implementation ###\n",
    "\n",
    "def separation_algorithm(y, f_i, G=G):\n",
    "    \"\"\"\n",
    "    Implements the separation algorithm for cut-set constraints based on the supplementary information.\n",
    "    \n",
    "    >>> Inputs:\n",
    "    y:                    Dictionary where keys are edge tuples (u, v) and values are their solution values i.e., y[e] gotten via current_sol[0] from above\n",
    "    f_i:                  Dictionary where keys are nodes and values are the solver solution for f_i[v] gotten via current_sol[2] from above\n",
    "    G:                    Graph object from Networkx of the current problem.\n",
    "\n",
    "    >>> Outputs:\n",
    "    delta_minus_S:       List of edges i.e., (u,v) that are in the named set as per the paper\n",
    "    v:                   Node at which the constraint is violated for\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"###################### EXECUTING SEPARATION ALGORITHM ###############################\")\n",
    "    \n",
    "    # Add edges with weights from y (solution values)\n",
    "    # Note: as per the documentation adding an edge that already exists updates the edge data.\n",
    "    for (u,v), sol_value in y.items():\n",
    "        G.add_edge(u, v, weight=sol_value)\n",
    "        \n",
    "    \n",
    "    # Solve the max-flow min-cut problem for each node with f_i[v] > 0\n",
    "    for v, flow_in in f_i.items():\n",
    "        if flow_in > 0:\n",
    "            \n",
    "            # Compute min-cut using the function from networkx\n",
    "            cut_value, (S, Not_S) = nx.minimum_cut(G, super_source, v, capacity=\"weight\")\n",
    "            \n",
    "            # If the cut weight is less than flow_in, add a violated constraint\n",
    "            if cut_value < flow_in:\n",
    "\n",
    "                print(\"$$$$$$$$$$$$$$$$$$$$$$$$$ WE FOUND A VIOLATED CONSTRAINT $$$$$$$$$$$$$$\")\n",
    "                print(f\"Violated constraint for node {v}: Cut separating {S} and {Not_S}\")\n",
    "\n",
    "                \n",
    "                # Define delta_minus_S in this case\n",
    "                delta_minus_S = [(u, v) for u in S for v in Not_S if G.has_edge(u, v)]\n",
    "\n",
    "                # Return a list that contains the violated constraint's data needed to add the cut into \n",
    "                # Xpress using the call back.\n",
    "                return (delta_minus_S, v)\n",
    "\n",
    "    # Note: This version returns the first violated constraint found; A possible extension is \n",
    "    #       to try if its better to return all violated constraints in a single potential solution. \n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def separation_cbpreintsol(prob, data, isheuristic, cutoff):\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@ cbpreintsol triggered @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "    # Get LP relaxation solution\n",
    "    lp_solution = []\n",
    "    prob.getlpsol(lp_solution, None, None, None)\n",
    "    \n",
    "    # Populate values from lp_solution using iteration which should be faster as it is just an O(1) process.\n",
    "    # Note: we could stop at f_i_temp if it gets too slow. \n",
    "    solution_iter = iter(lp_solution)\n",
    "    \n",
    "    for key in y_temp:\n",
    "        y_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in z_temp:\n",
    "        z_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in f_i_temp:\n",
    "        f_i_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in f_o_temp:\n",
    "        f_o_temp[key] = next(solution_iter)\n",
    "    \n",
    "    # Get the violated constraint data using the separation algorithm from above\n",
    "    violated_constraint_data = separation_algorithm(y_temp, f_i_temp)\n",
    "\n",
    "    # Check if there is a violated constraint\n",
    "    if violated_constraint_data:\n",
    "        \n",
    "        print(\"------------------------------ Solution Rejected -------------------------------\")\n",
    "\n",
    "        # There is a violated constraint so return 1/True i.e., reject this solution\n",
    "        # Note: From the research I've found the purpose of this callback is to just reject solutions\n",
    "        #       and not to add constraints to the problem dynamically. This is particularly relevant\n",
    "        #       for Andrew's part because he'll probably have to do it recursively outside the solver. \n",
    "        return (1, None)\n",
    "    \n",
    "    # Otherwise, return 0/False i.e., this solution does not violate a constraint so its good!\n",
    "    return (0, None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def separation_cboptnode(prob, data):\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@ cboptnode triggered @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    \n",
    "    # Get LP relaxation solution\n",
    "    lp_solution = []\n",
    "    prob.getlpsol(lp_solution, None, None, None)\n",
    "    \n",
    "    # Populate values from lp_solution using iteration which should be faster as it is just an O(1) process.\n",
    "    # Note: we could stop at f_i_temp if it gets too slow. \n",
    "    solution_iter = iter(lp_solution)\n",
    "    \n",
    "    for key in y_temp:\n",
    "        y_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in z_temp:\n",
    "        z_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in f_i_temp:\n",
    "        f_i_temp[key] = next(solution_iter)\n",
    "    \n",
    "    # for key in f_o_temp:\n",
    "    #     f_o_temp[key] = next(solution_iter)\n",
    "\n",
    "    \n",
    "    # Get the violated constraint data using the separation algorithm from above\n",
    "    violated_constraint_data = separation_algorithm(y_temp, f_i_temp)\n",
    "    \n",
    "    # If there is a violated constraint add it as a cut\n",
    "    if violated_constraint_data:\n",
    "        \n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!! Adding Cut !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "        # Unpack the tuple to get the data we want\n",
    "        delta_minus_S, v = violated_constraint_data  \n",
    "\n",
    "        # Translate the cut into the presolve index\n",
    "        colind, rowcoef = [], []\n",
    "        \n",
    "        drhsp, status = prob.presolverow(      rowtype = \"G\", # 'G' for >= constraints\n",
    "                                               origcolind = [prob.getIndex(y[e]) for e in delta_minus_S] + [prob.getIndex(f_i[v])], # Index values of original variables\n",
    "                                               origrowcoef = [1] * len(delta_minus_S) + [-1], # Coefficients for original variables\n",
    "                                               origrhs = 0, # Right-hand side of constraint in original variables\n",
    "                                               maxcoefs=prob.attributes.cols,\n",
    "                                               colind=colind, rowcoef=rowcoef # where to output the new ones\n",
    "                                        ) \n",
    "        \n",
    "        # Now we add the translated cut\n",
    "        prob.addcuts(\n",
    "                            cuttype=[1],  # General cut\n",
    "                            rowtype=['G'],  # Presolved row type\n",
    "                            rhs=[drhsp],  # Presolved RHS\n",
    "                            start=[0, len(colind)],  # Start indices\n",
    "                            colind=colind,  # Presolved column indices\n",
    "                            cutcoef=rowcoef  # Presolved coefficients\n",
    "                    )\n",
    "        \n",
    "\n",
    "        print(\"++++++++++++++++++++++++++++++ Cut Added! ++++++++++++++++++++++++++++++\")\n",
    "\n",
    "    # Continue solving\n",
    "    return (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00a848fb-9179-4698-af8f-67437ebd1beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FICO Xpress v9.4.2, Community, solve started 16:01:51, Feb 18, 2025\n",
      "Heap usage: 394KB (peak 394KB, 109KB system)\n",
      "Maximizing MILP noname using up to 14 threads and up to 15GB memory, with these control settings:\n",
      "OUTPUTLOG = 1\n",
      "NLPPOSTSOLVE = 1\n",
      "XSLP_DELETIONCONTROL = 0\n",
      "XSLP_OBJSENSE = -1\n",
      "Original problem has:\n",
      "        19 rows           15 cols           33 elements        15 entities\n",
      "Presolved problem has:\n",
      "         0 rows            0 cols            0 elements         0 entities\n",
      "LP relaxation tightened\n",
      "Presolve finished in 0 seconds\n",
      "Heap usage: 400KB (peak 409KB, 109KB system)\n",
      "Will try to keep branch and bound tree memory usage below 8.7GB\n",
      "Starting concurrent solve with dual (1 thread)\n",
      "\n",
      " Concurrent-Solve,   0s\n",
      "            Dual        \n",
      "    objective   dual inf\n",
      " D  40.000000   .0000000\n",
      "                        \n",
      "------- optimal --------\n",
      "Concurrent statistics:\n",
      "           Dual: 0 simplex iterations, 0.00s\n",
      "Optimal solution found\n",
      " \n",
      "   Its         Obj Value      S   Ninf  Nneg   Sum Dual Inf  Time\n",
      "     0         40.000000      D      0     0        .000000     0\n",
      "Dual solved problem\n",
      "  0 simplex iterations in 0.00 seconds at time 0\n",
      "\n",
      "Final objective                       : 4.000000000000000e+01\n",
      "  Max primal violation      (abs/rel) :       0.0 /       0.0\n",
      "  Max dual violation        (abs/rel) :       0.0 /       0.0\n",
      "  Max complementarity viol. (abs/rel) :       0.0 /       0.0\n",
      "\n",
      "Starting root cutting & heuristics\n",
      "Deterministic mode with up to 1 additional thread\n",
      " \n",
      " Its Type    BestSoln    BestBound   Sols    Add    Del     Gap     GInf   Time\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@ cboptnode triggered @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "###################### EXECUTING SEPARATION ALGORITHM ###############################\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$ WE FOUND A VIOLATED CONSTRAINT $$$$$$$$$$$$$$\n",
      "Violated constraint for node P1: Cut separating {'NDD1', 'SUPER'} and {'P2', 'P4', 'P1', 'P3'}\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!! Adding Cut !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "++++++++++++++++++++++++++++++ Cut Added! ++++++++++++++++++++++++++++++\n",
      " *** Search completed ***\n",
      "Problem is integer infeasible\n",
      "Uncrunching matrix\n",
      "  Solution time / primaldual integral :      0.01s/ 100.000000%\n",
      "  Number of solutions found / nodes   :         0 /         1\n",
      "?557 Error: Integer solution is not available\n"
     ]
    },
    {
     "ename": "SolverError",
     "evalue": "?557 Error: Integer solution is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 101\u001b[0m\n\u001b[0;32m     94\u001b[0m model\u001b[38;5;241m.\u001b[39msolve()\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Get the current solution\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m current_sol \u001b[38;5;241m=\u001b[39m ({e: model\u001b[38;5;241m.\u001b[39mgetSolution(y[e]) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m edges}, {c: model\u001b[38;5;241m.\u001b[39mgetSolution(z[c]) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m all_cycles}, {v: model\u001b[38;5;241m.\u001b[39mgetSolution(f_i[v]) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m nodes})\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Extract and print solution\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObjective Value:\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39mgetObjVal())\n",
      "\u001b[1;31mSolverError\u001b[0m: ?557 Error: Integer solution is not available"
     ]
    }
   ],
   "source": [
    "# Define the optimization model\n",
    "model = xp.problem()\n",
    "\n",
    "\n",
    "\n",
    "# Decision variables\n",
    "y = {e: xp.var(vartype=xp.binary, name=f\"y_{e}\") for e in edges}  # Edge selection\n",
    "z = {c: xp.var(vartype=xp.binary, name=f\"z_{c}\") for c in all_cycles}  # Cycle selection\n",
    "f_i = {v: xp.var(vartype=xp.binary) for v in nodes}  # Flow in decision variable\n",
    "f_o = {v: xp.var(vartype=xp.binary) for v in nodes}  # Flow out decision variable\n",
    "\n",
    "# Add decision variables\n",
    "model.addVariable(list(y.values()) + list(z.values())+ list(f_i.values()) + list(f_o.values()))\n",
    "\n",
    "\n",
    "\n",
    "# Xpress uses indexing when in callback thats why we need to create a dictionary for the ids. I suspect when you run this on actual data\n",
    "# you would want to do this in another code cell just so that it isn't repeated every time you solve the model for debugging. \n",
    "# e.g., id_vars[(\"y\", ('NDD1', 'P1') )] = 0 i.e., the decision variable to connect nodes NDD1 and P1 is the first decision variable in Xpress.\n",
    "\n",
    "# Initialize id_vars dictionary and counter to assign sequential values\n",
    "id_vars = {}\n",
    "counter = 0\n",
    "\n",
    "# Populate id_vars with (\"y\", key) tuples\n",
    "for key in y.keys():\n",
    "    id_vars[(\"y\", key)] = counter\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "# Populate id_vars with (\"z\", key) tuples\n",
    "for key in z.keys():\n",
    "    id_vars[(\"z\", key)] = counter\n",
    "    counter += 1\n",
    "\n",
    "# Populate id_vars with (\"f_i\", key) tuples\n",
    "for key in f_i.keys():\n",
    "    id_vars[(\"f_i\", key)] = counter\n",
    "    counter += 1\n",
    "\n",
    "# Populate id_vars with (\"f_o\", key) tuples\n",
    "for key in f_o.keys():\n",
    "    id_vars[(\"f_o\", key)] = counter\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "# Create temporary storage for the callback solutions to be used:\n",
    "y_temp = {e: 0 for e in edges}\n",
    "z_temp = {c: 0 for c in all_cycles} \n",
    "f_i_temp = {v: 0 for v in nodes}  \n",
    "f_o_temp = {v: 0 for v in nodes}  \n",
    "\n",
    "\n",
    "# Define the objective function which is to maximize sum of weights of selected edges and cycles\n",
    "model.setObjective(xp.Sum(edges[e] * y[e] for e in edges) + xp.Sum(all_cycles[c] * z[c] for c in all_cycles), sense=xp.maximize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constraints:\n",
    "\n",
    "# 1. Defining f_i and f_o i.e., the incoming and outgoing kidneys to a node v\n",
    "for v in nodes:\n",
    "    model.addConstraint(xp.Sum([y[e] for e in edges if e[1] == v]) == f_i[v])\n",
    "    model.addConstraint(xp.Sum([y[e] for e in edges if e[0] == v]) == f_o[v])\n",
    "\n",
    "# 2. Ensure that if a node is in an actived cycle, the associated edges that involve it are turned off\n",
    "for v in pairs:\n",
    "    model.addConstraint(f_o[v] + xp.Sum([z[c] for c in all_cycles if v in c]) <= f_i[v] + xp.Sum([z[c] for c in all_cycles if v in c]))\n",
    "    model.addConstraint(f_i[v] + xp.Sum([z[c] for c in all_cycles if v in c]) <= 1)\n",
    "\n",
    "# 3. Ensure that altruistic donors donate at most one kidney  \n",
    "for v in altruistic_donors:\n",
    "    model.addConstraint(f_o[v] <= 1)\n",
    "\n",
    "\n",
    "# # Checking if the feasible solution can be spit out which it does!\n",
    "# for e in edges:\n",
    "#     model.addConstraint(y[e] == 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add the call back function to detect and add violated constraints during LP relaxation\n",
    "model.addcbpreintsol(separation_cbpreintsol, None, 1)\n",
    "model.addcboptnode(separation_cboptnode, None, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Solve the model\n",
    "model.solve()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the current solution\n",
    "current_sol = ({e: model.getSolution(y[e]) for e in edges}, {c: model.getSolution(z[c]) for c in all_cycles}, {v: model.getSolution(f_i[v]) for v in nodes})\n",
    "\n",
    "# Extract and print solution\n",
    "print(\"Objective Value:\", model.getObjVal())\n",
    "print([type(model.getSolution(y[e])) for e in edges])\n",
    "selected_edges = [e for e in edges if model.getSolution(y[e]) > 0.5]\n",
    "selected_cycles = [c for c in all_cycles if model.getSolution(z[c]) > 0.5]\n",
    "print(\"Selected Edges:\", selected_edges)\n",
    "print(\"Selected Cycles:\", selected_cycles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
