{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c7341e6-3dc4-4851-a4c0-0329649b174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xpress as xp\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "12f78ada-fd8e-4541-86df-e081a8121298",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell contains the callbacks and their implementation ###\n",
    "\n",
    "def separation_algorithm(y, f_i, G=G):\n",
    "    \"\"\"\n",
    "    Implements the separation algorithm for cut-set constraints based on the supplementary information.\n",
    "    \n",
    "    >>> Inputs:\n",
    "    y:                    Dictionary where keys are edge tuples (u, v) and values are their solution values i.e., y[e] gotten via current_sol[0] from above\n",
    "    f_i:                  Dictionary where keys are nodes and values are the solver solution for f_i[v] gotten via current_sol[2] from above\n",
    "    G:                    Graph object from Networkx of the current problem.\n",
    "\n",
    "    >>> Outputs:\n",
    "    delta_minus_S:       List of edges i.e., (u,v) that are in the named set as per the paper\n",
    "    v:                   Node at which the constraint is violated for\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"###################### EXECUTING SEPARATION ALGORITHM ###############################\")\n",
    "    \n",
    "    # Add edges with weights from y (solution values)\n",
    "    # Note: as per the documentation adding an edge that already exists updates the edge data.\n",
    "    for (u,v), sol_value in y.items():\n",
    "        G.add_edge(u, v, weight=sol_value)\n",
    "        \n",
    "    \n",
    "    # Solve the max-flow min-cut problem for each node with f_i[v] > 0\n",
    "    for v, flow_in in f_i.items():\n",
    "        if flow_in > 0:\n",
    "            \n",
    "            # Compute min-cut using the function from networkx\n",
    "            cut_value, (S, Not_S) = nx.minimum_cut(G, super_source, v, capacity=\"weight\")\n",
    "            \n",
    "            # If the cut weight is less than flow_in, add a violated constraint\n",
    "            if cut_value < flow_in:\n",
    "\n",
    "                print(\"$$$$$$$$$$$$$$$$$$$$$$$$$ WE FOUND A VIOLATED CONSTRAINT $$$$$$$$$$$$$$\")\n",
    "                print(f\"Violated constraint for node {v}: Cut separating {S} and {Not_S}\")\n",
    "\n",
    "                \n",
    "                # Define delta_minus_S in this case\n",
    "                delta_minus_S = [(u, v) for u in S for v in Not_S if G.has_edge(u, v)]\n",
    "\n",
    "                # Return a list that contains the violated constraint's data needed to add the cut into \n",
    "                # Xpress using the call back.\n",
    "                return [delta_minus_S, v]\n",
    "\n",
    "    # Note: This version returns the first violated constraint found; A possible extension is \n",
    "    #       to try if its better to return all violated constraints in a single potential solution. \n",
    "    return []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def separation_cbpreintsol(prob, data, isheuristic, cutoff):\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@ Callback triggered @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    \n",
    "    # Get LP relaxation solution\n",
    "    lp_solution = []\n",
    "    prob.getlpsol(lp_solution, None, None, None)\n",
    "    \n",
    "    # Populate values from lp_solution using iteration which should be faster as it is just an O(1) process.\n",
    "    # Note: we could stop at f_i_temp if it gets too slow. \n",
    "    solution_iter = iter(lp_solution)\n",
    "    \n",
    "    for key in y_temp:\n",
    "        y_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in z_temp:\n",
    "        z_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in f_i_temp:\n",
    "        f_i_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in f_o_temp:\n",
    "        f_o_temp[key] = next(solution_iter)\n",
    "    \n",
    "    # Get the violated constraint data using the separation algorithm from above\n",
    "    violated_constraint_data = separation_algorithm(y_temp, f_i_temp)\n",
    "\n",
    "    # If there is a violated constraint add it as a cut\n",
    "    if violated_constraint_data:\n",
    "\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!! Adding Cut !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "        \n",
    "        # Extract the id of the decision variables involved in this cut\n",
    "        id_f_i_v = id_vars[(\"f_i\",violated_cut[1])]\n",
    "        id_delta_minus_S = [id_vars[(\"y\",e)] for e in violated_cut[0]]\n",
    "\n",
    "        # Fill out the required inputs to the addcuts() function\n",
    "        colind = id_delta_minus_S + [id_f_i_v]  # Indices of variables in cut\n",
    "        cutcoef = [1] * len(y_indices) + [-1]  # Coefficients\n",
    "        rhs = 0  # Reformulated constraint sum y[e] - f_i[v] >= 0\n",
    "\n",
    "        # Add the cut\n",
    "        model.addcuts(1, 'G', rhs, 1, colind, cutcoef) # not sure what 1 and 1 do\n",
    "\n",
    "        # Return True i.e, you cannot use this solution because it violated a constraint\n",
    "        return (True, None) \n",
    "    \n",
    "    # Otherwise, return False i.e., this solution does not violate a constraint\n",
    "    return (False, None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def separation_cboptnode(prob, data):\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@ Callback triggered @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    \n",
    "    # Get LP relaxation solution\n",
    "    lp_solution = []\n",
    "    prob.getlpsol(lp_solution, None, None, None)\n",
    "    \n",
    "    # Populate values from lp_solution using iteration which should be faster as it is just an O(1) process.\n",
    "    # Note: we could stop at f_i_temp if it gets too slow. \n",
    "    solution_iter = iter(lp_solution)\n",
    "    \n",
    "    for key in y_temp:\n",
    "        y_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in z_temp:\n",
    "        z_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in f_i_temp:\n",
    "        f_i_temp[key] = next(solution_iter)\n",
    "    \n",
    "    for key in f_o_temp:\n",
    "        f_o_temp[key] = next(solution_iter)\n",
    "    \n",
    "    # Get the violated constraint data using the separation algorithm from above\n",
    "    violated_constraint_data = separation_algorithm(y_temp, f_i_temp)\n",
    "\n",
    "    # If there is a violated constraint add it as a cut\n",
    "    if violated_constraint_data:\n",
    "\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!! Adding Cut !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "        \n",
    "        # Extract the id of the decision variables involved in this cut\n",
    "        id_f_i_v = id_vars[(\"f_i\",violated_cut[1])]\n",
    "        id_delta_minus_S = [id_vars[(\"y\",e)] for e in violated_cut[0]]\n",
    "\n",
    "        # Fill out the required inputs to the addcuts() function\n",
    "        colind = id_delta_minus_S + [id_f_i_v]  # Indices of variables in cut\n",
    "        cutcoef = [1] * len(y_indices) + [-1]  # Coefficients\n",
    "        rhs = 0  # Reformulated constraint sum y[e] - f_i[v] >= 0\n",
    "\n",
    "        # Add the cut\n",
    "        model.addcuts(1, 'G', rhs, 1, colind, cutcoef) # not sure what 1 and 1 do\n",
    "\n",
    "        # Return 100 i.e, you cannot use this solution because it violated a constraint\n",
    "        return (100) \n",
    "    \n",
    "    # Otherwise, return 0 i.e., this solution does not violate a constraint\n",
    "    return (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "00a848fb-9179-4698-af8f-67437ebd1beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FICO Xpress v9.4.2, Community, solve started 17:58:21, Feb 13, 2025\n",
      "Heap usage: 394KB (peak 394KB, 234KB system)\n",
      "Maximizing MILP noname using up to 14 threads and up to 15GB memory, with these control settings:\n",
      "OUTPUTLOG = 1\n",
      "NLPPOSTSOLVE = 1\n",
      "XSLP_DELETIONCONTROL = 0\n",
      "XSLP_OBJSENSE = -1\n",
      "Original problem has:\n",
      "        19 rows           15 cols           33 elements        15 entities\n",
      "Presolved problem has:\n",
      "         0 rows            0 cols            0 elements         0 entities\n",
      "LP relaxation tightened\n",
      "Presolve finished in 0 seconds\n",
      "Heap usage: 400KB (peak 409KB, 234KB system)\n",
      "Will try to keep branch and bound tree memory usage below 8.7GB\n",
      "Starting concurrent solve with dual (1 thread)\n",
      "\n",
      " Concurrent-Solve,   0s\n",
      "            Dual        \n",
      "    objective   dual inf\n",
      " D  40.000000   .0000000\n",
      "                        \n",
      "------- optimal --------\n",
      "Concurrent statistics:\n",
      "           Dual: 0 simplex iterations, 0.00s\n",
      "Optimal solution found\n",
      " \n",
      "   Its         Obj Value      S   Ninf  Nneg   Sum Dual Inf  Time\n",
      "     0         40.000000      D      0     0        .000000     0\n",
      "Dual solved problem\n",
      "  0 simplex iterations in 0.00 seconds at time 0\n",
      "\n",
      "Final objective                       : 4.000000000000000e+01\n",
      "  Max primal violation      (abs/rel) :       0.0 /       0.0\n",
      "  Max dual violation        (abs/rel) :       0.0 /       0.0\n",
      "  Max complementarity viol. (abs/rel) :       0.0 /       0.0\n",
      "\n",
      "Starting root cutting & heuristics\n",
      "Deterministic mode with up to 1 additional thread\n",
      " \n",
      " Its Type    BestSoln    BestBound   Sols    Add    Del     Gap     GInf   Time\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@ Callback triggered @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "###################### EXECUTING SEPARATION ALGORITHM ###############################\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$ WE FOUND A VIOLATED CONSTRAINT $$$$$$$$$$$$$$\n",
      "Violated constraint for node P1: Cut separating {'NDD1', 'SUPER'} and {'P3', 'P4', 'P1', 'P2'}\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!! Adding Cut !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "*           40.000000    40.000000      1                 -0.00%       0      0\n",
      " *** Search completed ***\n",
      "Uncrunching matrix\n",
      "Final MIP objective                   : 4.000000000000000e+01\n",
      "Final MIP bound                       : 4.000000000000000e+01\n",
      "  Solution time / primaldual integral :      0.00s/ 96.770911%\n",
      "  Number of solutions found / nodes   :         1 /         1\n",
      "  Max primal violation      (abs/rel) :       0.0 /       0.0\n",
      "  Max integer violation     (abs    ) :       0.0\n",
      "Objective Value: 40.0\n",
      "[<class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'float'>]\n",
      "Selected Edges: [('P1', 'P2'), ('P2', 'P3'), ('P3', 'P4'), ('P4', 'P1')]\n",
      "Selected Cycles: []\n"
     ]
    }
   ],
   "source": [
    "# What we need to feed this model is the following:\n",
    "# 1- List of donor-receipient pairs\n",
    "# 2- List of altruisitic donors\n",
    "# 3- List of nodes = donor-receipient pairs + altruisitic donors\n",
    "# 4- Dictionary of edges with key (\"node1\",\"node2\") and value is the weight of the edge\n",
    "# 5- Dictionary of cycles with key (edge1,edge2,edge3,...) and value is the weight of the cycle i.e., sum of edges in the cycle up to and including length k\n",
    "\n",
    "# pairs = [\"P1\", \"P2\", \"P3\"] \n",
    "# altruistic_donors = [\"NDD1\"]\n",
    "# nodes = pairs + altruistic_donors\n",
    "# edges = {(\"NDD1\", \"P1\"): 10, \n",
    "#          (\"NDD1\", \"P2\"): 8,\n",
    "#          (\"P1\", \"P3\"): 8, \n",
    "#          (\"P2\", \"P3\"): 9,\n",
    "#          (\"P3\", \"P1\"): 6,\n",
    "#          (\"P1\", \"P2\"): 6}\n",
    "# all_cycles = {}\n",
    "\n",
    "\n",
    "pairs = [\"P1\", \"P2\", \"P3\", \"P4\"] \n",
    "altruistic_donors = [\"NDD1\"]\n",
    "nodes = pairs + altruistic_donors\n",
    "edges = {(\"NDD1\", \"P1\"): 2,\n",
    "         (\"P1\", \"P2\"): 10, \n",
    "         (\"P2\", \"P3\"): 10,\n",
    "         (\"P3\", \"P4\"): 10,\n",
    "         (\"P4\", \"P1\"): 10\n",
    "}\n",
    "all_cycles = {}\n",
    "\n",
    "\n",
    "# Create the graph outside the separation algorithm and feed it in whenever we use it so that it doesn't create it every time\n",
    "# instead, it just updates the weights i.e., you only create the graph once!\n",
    "\n",
    "# Construct the directed graph G = (V, E, w) based on supplementary information definition \n",
    "G = nx.DiGraph()\n",
    "for node in nodes:\n",
    "    G.add_node(node)\n",
    "\n",
    "# Add super source 'SUPER' and connect to all NDDs\n",
    "super_source = \"SUPER\"\n",
    "G.add_node(super_source)\n",
    "for u in altruistic_donors:\n",
    "    G.add_edge(super_source, u, weight=1)\n",
    "\n",
    "\n",
    "# Define the optimization model\n",
    "model = xp.problem()\n",
    "\n",
    "\n",
    "\n",
    "# Decision variables\n",
    "y = {e: xp.var(vartype=xp.binary, name=f\"y_{e}\") for e in edges}  # Edge selection\n",
    "z = {c: xp.var(vartype=xp.binary, name=f\"z_{c}\") for c in all_cycles}  # Cycle selection\n",
    "f_i = {v: xp.var(vartype=xp.binary) for v in nodes}  # Flow in decision variable\n",
    "f_o = {v: xp.var(vartype=xp.binary) for v in nodes}  # Flow out decision variable\n",
    "\n",
    "# Add decision variables\n",
    "model.addVariable(list(y.values()) + list(z.values())+ list(f_i.values()) + list(f_o.values()))\n",
    "\n",
    "\n",
    "\n",
    "# Xpress uses indexing when in callback thats why we need to create a dictionary for the ids. I suspect when you run this on actual data\n",
    "# you would want to do this in another code cell just so that it isn't repeated every time you solve the model for debugging. \n",
    "# e.g., id_vars[(\"y\", ('NDD1', 'P1') )] = 0 i.e., the decision variable to connect nodes NDD1 and P1 is the first decision variable in Xpress.\n",
    "\n",
    "# Initialize id_vars dictionary and counter to assign sequential values\n",
    "id_vars = {}\n",
    "counter = 0\n",
    "\n",
    "# Populate id_vars with (\"y\", key) tuples\n",
    "for key in y.keys():\n",
    "    id_vars[(\"y\", key)] = counter\n",
    "    counter += 1\n",
    "    \n",
    "\n",
    "# Populate id_vars with (\"z\", key) tuples\n",
    "for key in z.keys():\n",
    "    id_vars[(\"z\", key)] = counter\n",
    "    counter += 1\n",
    "\n",
    "# Populate id_vars with (\"f_i\", key) tuples\n",
    "for key in f_i.keys():\n",
    "    id_vars[(\"f_i\", key)] = counter\n",
    "    counter += 1\n",
    "\n",
    "# Populate id_vars with (\"f_o\", key) tuples\n",
    "for key in f_o.keys():\n",
    "    id_vars[(\"f_o\", key)] = counter\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "# Create temporary storage for the callback solutions to be used:\n",
    "y_temp = {e: 0 for e in edges}\n",
    "z_temp = {c: 0 for c in all_cycles} \n",
    "f_i_temp = {v: 0 for v in nodes}  \n",
    "f_o_temp = {v: 0 for v in nodes}  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the objective function which is to maximize sum of weights of selected edges and cycles\n",
    "model.setObjective(xp.Sum(edges[e] * y[e] for e in edges) + xp.Sum(all_cycles[c] * z[c] for c in all_cycles), sense=xp.maximize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Constraints:\n",
    "\n",
    "# 1. Defining f_i and f_o i.e., the incoming and outgoing kidneys to a node v\n",
    "for v in nodes:\n",
    "    model.addConstraint(xp.Sum([y[e] for e in edges if e[1] == v]) == f_i[v])\n",
    "    model.addConstraint(xp.Sum([y[e] for e in edges if e[0] == v]) == f_o[v])\n",
    "\n",
    "# 2. Ensure that if a node is in an actived cycle, the associated edges that involve it are turned off\n",
    "for v in pairs:\n",
    "    model.addConstraint(f_o[v] + xp.Sum([z[c] for c in all_cycles if v in c]) <= f_i[v] + xp.Sum([z[c] for c in all_cycles if v in c]))\n",
    "    model.addConstraint(f_i[v] + xp.Sum([z[c] for c in all_cycles if v in c]) <= 1)\n",
    "\n",
    "# 3. Ensure that altruistic donors donate at most one kidney  \n",
    "for v in altruistic_donors:\n",
    "    model.addConstraint(f_o[v] <= 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add the call back function to detect and add violated constraints during LP relaxation\n",
    "# Note: I still do not know how the numbers work but I tried them all and they work haha!\n",
    "# model.addcbpreintsol(separation_cbpreintsol, None, 1)\n",
    "model.addcboptnode(separation_cboptnode, None, 3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Solve the model\n",
    "model.solve()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the current solution\n",
    "current_sol = ({e: model.getSolution(y[e]) for e in edges}, {c: model.getSolution(z[c]) for c in all_cycles}, {v: model.getSolution(f_i[v]) for v in nodes})\n",
    "\n",
    "# Extract and print solution\n",
    "print(\"Objective Value:\", model.getObjVal())\n",
    "print([type(model.getSolution(y[e])) for e in edges])\n",
    "selected_edges = [e for e in edges if model.getSolution(y[e]) > 0.5]\n",
    "selected_cycles = [c for c in all_cycles if model.getSolution(z[c]) > 0.5]\n",
    "print(\"Selected Edges:\", selected_edges)\n",
    "print(\"Selected Cycles:\", selected_cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ec052-3493-4f4b-a006-60dac8d7c2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
